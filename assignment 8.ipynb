{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes - Transparency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from :https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame\n",
    "\n",
    "There are 957 objects and 9 features in the dataset\n",
    "This database encodes the complete set of possible board configurations at the end of tic-tac-toe games, where \"x\" is assumed to have played first. The target concept is \"win for x\" \n",
    "(i.e., true when \"x\" has one of 8 possible ways to create a \"three-in-a-row\"). \n",
    "\n",
    "Attribute Information: (x=player x has taken, o=player o has taken, b=blank)\n",
    "1. top-left-square: {x,o,b}\n",
    "2. top-middle-square: {x,o,b}\n",
    "3. top-right-square: {x,o,b}\n",
    "4. middle-left-square: {x,o,b}\n",
    "5. middle-middle-square: {x,o,b}\n",
    "6. middle-right-square: {x,o,b}\n",
    "7. bottom-left-square: {x,o,b}\n",
    "8. bottom-middle-square: {x,o,b}\n",
    "9. bottom-right-square: {x,o,b}\n",
    "10. Class: {positive,negative}\n",
    "\n",
    "\n",
    "*note: class distribution[negative,positive]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('tic-tac-toe.data')\n",
    "df = df.rename(index=str, columns={\"positive\": \"class\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Binarize feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = pd.get_dummies(df, columns=[\"x\", \"x.1\",\"x.2\",\"x.3\",\"o\",\"o.1\",\"x.4\",\"o.2\",\"o.3\"], \n",
    "               prefix=[\"top-left-square\", \"top-middle-square\",\"top-right-square\",\"middle-left-square\",\"middle-middle-square\"\n",
    "                       ,\"middle-right-square\",\"bottom-left-square\",\"bottom-middle-square\",\"bottom-right-square\"])\n",
    "\n",
    "cleanup_nums = {\"class\":  {\"positive\": 1, \"negative\": 0}}\n",
    "\n",
    "df_new.replace(cleanup_nums, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Split data to train_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = df_new.iloc[:,1:28].values\n",
    "y = df_new.iloc[:,0:1].values\n",
    "feature_name=list(df_new.drop('class',1))\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size = 0.33, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: fit data to BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy_score of train set 0.700468018721\n",
      "The accuracy_score of test set 0.721518987342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, Y_train.ravel())\n",
    "y_pred = nb.predict(X_test)\n",
    "print(\"The accuracy_score of train set\", nb.score(X_train,Y_train))\n",
    "print(\"The accuracy_score of test set\", nb.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Get feature distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_log_prob_ = nb.feature_log_prob_\n",
    "feature_yes_prob = np.exp(feature_log_prob_)\n",
    "feature_yes_ratio=[]\n",
    "for x in range(0,len(feature_yes_prob[0,])):\n",
    "    feature_yes_ratio.append( [np.log(feature_yes_prob[1,x]/feature_yes_prob[0,x])])\n",
    "feature_no_prob_neg =[1-x for x in feature_yes_prob[0,]]\n",
    "feature_no_prob_pos =[1-x for x in feature_yes_prob[1,]]\n",
    "feature_no_prob = [feature_no_prob_neg,feature_no_prob_pos]\n",
    "feature_no_ratio=[]\n",
    "for x in range(0,len(feature_no_prob[0])):\n",
    "    feature_no_ratio.append( [np.log(feature_no_prob[1][x]/feature_no_prob[0][x])])\n",
    "feature_ratio = [feature_no_ratio,feature_yes_ratio]\n",
    "feature_ratio= np.array(feature_ratio).reshape(2,27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Define total pos/neg log-evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_evidence(obj):\n",
    "    positive_evidence_list = []\n",
    "    negative_evidence_list = []\n",
    "    total_positive_evidence = []\n",
    "    total_negative_evidence = []\n",
    "    for i, value in enumerate(obj):#i means number of features , value means value of i-th feature\n",
    "        total_evidence_list.append(feature_ratio[value][i])\n",
    "        if feature_ratio[value][i]>0 :\n",
    "            positive_evidence_list.append(feature_ratio[value][i])\n",
    "        else:\n",
    "            negative_evidence_list.append(feature_ratio[value][i])\n",
    "    total_positive_evidence = sum(positive_evidence_list)\n",
    "    total_negative_evidence = sum(negative_evidence_list)\n",
    "    return(total_negative_evidence,total_positive_evidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7: Define top 3 features with most of pos/neg evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_top_feature(obj):\n",
    "    feature_negative_index =[]\n",
    "    feature_positive_index =[]\n",
    "    feature_positive_index= np.argpartition(total_evidence_list, -3)[-3:]\n",
    "    feature_negative_index = np.argpartition(total_evidence_list, 3)[:3]\n",
    "    print('(d)top 3 features values that contribute most to the positive evidence')\n",
    "    for i in range(0,3):\n",
    "        print(feature_name[feature_positive_index[i]],obj[feature_positive_index[i]])\n",
    "    print('(e)top 3 features values that contribute most to the negative evidence')\n",
    "    for i in range(0,3):\n",
    "        print(feature_name[feature_negative_index[i]],obj[feature_negative_index[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Get the following values from no.1 to no.5 objects\n",
    "a) the total positive log-evidence <br/>\n",
    "b) the total negative log-evidence <br/>\n",
    "c) probability distribution <br/>\n",
    "d) top 3 features values that contribute most to the positive evidence <br/>\n",
    "e) top 3 feature values that contribute the most to the negative evidence <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no.1 : The most positive object with respect to the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a)the total positive log-evidence 4.7197885665\n",
      "(b)the total negative log-evidence -0.572949307799\n",
      "(c)probability distribution [ 0.00836624  0.99163376]\n",
      "(d)top 3 features values that contribute most to the positive evidence\n",
      "bottom-right-square_b 1\n",
      "middle-middle-square_x 1\n",
      "middle-middle-square_o 0\n",
      "(e)top 3 features values that contribute most to the negative evidence\n",
      "top-middle-square_b 0\n",
      "middle-right-square_o 0\n",
      "bottom-right-square_x 0\n"
     ]
    }
   ],
   "source": [
    "total_evidence_list = []\n",
    "predict_proba = nb.predict_proba(X_test)\n",
    "positive_object_index = np.argmax(predict_proba[:,1])\n",
    "\n",
    "a_obj = X_test[positive_object_index,]\n",
    "total = log_evidence(a_obj)\n",
    "print('(a)the total positive log-evidence',total[1])\n",
    "print('(b)the total negative log-evidence',total[0])\n",
    "print(\"(c)probability distribution\",predict_proba[positive_object_index,])\n",
    "find_top_feature(a_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no.2 : The most negative object with respect to the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a)the total positive log-evidence 0.724058792054\n",
      "(b)the total negative log-evidence -4.82874019321\n",
      "(c)probability distribution [ 0.97000794  0.02999206]\n",
      "(d)top 3 features values that contribute most to the positive evidence\n",
      "bottom-middle-square_x 0\n",
      "top-right-square_o 0\n",
      "top-right-square_x 1\n",
      "(e)top 3 features values that contribute most to the negative evidence\n",
      "middle-middle-square_o 1\n",
      "middle-middle-square_x 0\n",
      "bottom-left-square_o 1\n"
     ]
    }
   ],
   "source": [
    "total_evidence_list = []\n",
    "negative_object_index = np.argmax(predict_proba[:,0])\n",
    "\n",
    "b_obj = X_test[negative_object_index,]\n",
    "total = log_evidence(b_obj)\n",
    "print('(a)the total positive log-evidence',total[1])\n",
    "print('(b)the total negative log-evidence',total[0])\n",
    "print(\"(c)probability distribution\",predict_proba[negative_object_index,])\n",
    "find_top_feature(b_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no.3 : The object that has the largest positive evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a)the total positive log-evidence 4.7197885665\n",
      "(b)the total negative log-evidence -0.572949307799\n",
      "(c)probability distribution [ 0.00836624  0.99163376]\n",
      "(d)top 3 features values that contribute most to the positive evidence\n",
      "bottom-right-square_b 1\n",
      "middle-middle-square_x 1\n",
      "middle-middle-square_o 0\n",
      "(e)top 3 features values that contribute most to the negative evidence\n",
      "top-middle-square_b 0\n",
      "middle-right-square_o 0\n",
      "bottom-right-square_x 0\n"
     ]
    }
   ],
   "source": [
    "total_evidence_list = []\n",
    "pos_evidence_testset_list = []\n",
    "neg_evidence_testset_list = []\n",
    "for x in range(0,len(X_test[:,0])):\n",
    "    total_evidence_list = []\n",
    "    total = log_evidence(X_test[x,])\n",
    "    pos_evidence_testset_list.append(total[1])\n",
    "    neg_evidence_testset_list.append(total[0])\n",
    "largest_pos_evidence_index = np.argmax(pos_evidence_testset_list)#3\n",
    "\n",
    "total_evidence_list = []\n",
    "c_obj = X_test[largest_pos_evidence_index,]\n",
    "total = log_evidence(c_obj)\n",
    "print('(a)the total positive log-evidence',total[1])\n",
    "print('(b)the total negative log-evidence',total[0])\n",
    "print(\"(c)probability distribution\",predict_proba[largest_pos_evidence_index,])\n",
    "find_top_feature(c_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no.4 : The object that has the largest negative evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a)the total positive log-evidence 0.724058792054\n",
      "(b)the total negative log-evidence -4.82874019321\n",
      "(c)probability distribution [ 0.97000794  0.02999206]\n",
      "(d)top 3 features values that contribute most to the positive evidence\n",
      "bottom-middle-square_x 0\n",
      "top-right-square_o 0\n",
      "top-right-square_x 1\n",
      "(e)top 3 features values that contribute most to the negative evidence\n",
      "middle-middle-square_o 1\n",
      "middle-middle-square_x 0\n",
      "bottom-left-square_o 1\n"
     ]
    }
   ],
   "source": [
    "total_evidence_list = []\n",
    "largest_neg_evidence_index = np.argmin(neg_evidence_testset_list)\n",
    "\n",
    "d_obj = X_test[largest_neg_evidence_index,]\n",
    "total = log_evidence(d_obj)\n",
    "print('(a)the total positive log-evidence',total[1])\n",
    "print('(b)the total negative log-evidence',total[0])\n",
    "print(\"(c)probability distribution\",predict_proba[largest_neg_evidence_index,])\n",
    "find_top_feature(d_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no.5: The most uncertain object (the probabilities are closest to 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a)the total positive log-evidence 2.34181134155\n",
      "(b)the total negative log-evidence -2.97538386302\n",
      "(c)probability distribution [ 0.50131571  0.49868429]\n",
      "(d)top 3 features values that contribute most to the positive evidence\n",
      "top-middle-square_o 1\n",
      "top-right-square_x 1\n",
      "bottom-left-square_x 1\n",
      "(e)top 3 features values that contribute most to the negative evidence\n",
      "middle-middle-square_o 1\n",
      "middle-middle-square_x 0\n",
      "bottom-right-square_o 1\n"
     ]
    }
   ],
   "source": [
    "total_evidence_list = []\n",
    "ratio = []\n",
    "for x in range(0,len(predict_proba[:,0])):\n",
    "    ratio.append( predict_proba[x,1]/predict_proba[x,0])\n",
    "ratio = np.array(ratio)\n",
    "new_ratio = np.abs(ratio-1)\n",
    "neural_index = np.argmin(new_ratio)\n",
    "\n",
    "e_obj = X_test[neural_index,]\n",
    "total = log_evidence(e_obj)\n",
    "print('(a)the total positive log-evidence',total[1])\n",
    "print('(b)the total negative log-evidence',total[0])\n",
    "print(\"(c)probability distribution\",predict_proba[neural_index,])\n",
    "find_top_feature(e_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
